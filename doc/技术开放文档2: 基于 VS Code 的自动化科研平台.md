技术开发文档：基于 VS Code 的自动化科研平台
项目 gemini-fullstack-langgraph-quickstart 升级规划
第1章：愿景与核心理念
本规划旨在将 gemini-fullstack-langgraph-quickstart 项目从一个技术演示原型，升级为一个创新的、企业级的自动化科研平台。其核心战略是放弃构建独立的Web前端，全面转向“VS Code即平台”的理念。

我们将开发一个功能强大的 VS Code 插件，将AI驱动的科研能力深度嵌入研究人员既有的工作流中。这种原生集成的方式，不仅能极大地降低用户的学习成本，更能让AI代理实时访问用户的完整项目上下文（代码、数据、笔记），从而提供远比孤立Web应用更加精准、智能的辅助，将平台从一个“聊天机器人”升格为一个真正的“上下文感知科研助理”。

第2章：统一系统架构
平台将采用模块化的四支柱架构，确保系统的健壮性、可扩展性和可维护性。

2.1 宏观视图：四支柱架构
VS Code 前端层: 完全运行在 VS Code 环境中，由 Node.js 插件主进程和基于 React 的 Webview 视图构成，负责所有用户交互。

FastAPI 后端层: 平台的大脑，使用 Python 和 FastAPI 构建，承载所有核心AI逻辑，并通过API对外提供服务。

PostgreSQL 数据库层: 平台的持久化存储中心，通过集成 pgvector 扩展，高效支持 RAG 所需的向量搜索和传统结构化数据存储。

集成生态系统: 深度集成一系列外部服务，包括用于版本控制的 GitHub、用于文献管理的 Zotero 以及各种学术数据库API（如 arXiv, PubMed）。

2.2 通信与数据流：混合模式
平台前后端将采用 RESTful API 和 WebSocket 相结合的混合通信模式：

RESTful API: 用于处理无状态、一次性的命令式交互，如启动新任务、获取项目初始状态等。

WebSockets: 用于实现低延迟、实时的双向通信，包括流式传输AI的“思考链”、动态更新编辑器中的文档内容，以及实现需要用户决策的“人在环路”（Human-in-the-Loop, HITL）交互。

2.3 技术栈选型
组件

技术选型

战略依据

前端UI

React + @vscode/webview-ui-toolkit

利用成熟的React生态，并采用官方UI库确保与VS Code原生界面的视觉与行为统一性。

前端逻辑

TypeScript / Node.js (VS Code Extension)

使用TypeScript进行类型安全的插件开发，并利用VS Code丰富的API实现对编辑器的深度控制。

后端API框架

Python + FastAPI

以其卓越的性能和易用性，快速构建健壮、文档齐全的AI密集型API服务。

后端AI代理

LangGraph

核心AI引擎。其图结构能创建复杂的循环工作流，完美契合科研的迭代特性，并为HITL提供原生支持。

数据库

PostgreSQL + pgvector

统一存储结构化数据和向量数据，简化架构，避免维护独立的向量数据库，提高RAG流程效率。

数据库ORM

SQLAlchemy

Python生态中最成熟的ORM库，提供强大灵活的数据库交互抽象层。

LLM编排

LiteLLM

提供统一接口调用超100种LLM，使平台可在不同模型间轻松切换，增强灵活性。

版本控制

Git / GitHub / GitHub Actions

实现“科研即代码”，利用Actions自动化研究流程，利用Git提供完整的可追溯性。

部署容器化

Docker / Docker Compose

确保开发、测试和生产环境的一致性，通过一个配置文件即可编排和启动整个平台。

第3章：前端体验：科研集成开发环境 (IDE)
我们将通过VS Code插件，将标准编辑器改造为一个专为科研设计的三栏式集成开发环境。

左栏：研究资产库 (侧边栏 TreeView)

实现: 通过VS Code TreeView API注册一个新的侧边栏视图。

功能: 集中展示所有研究资源，如已发现的文献、项目知识库文件（笔记、数据、脚本），并可选择性同步Zotero文库。

中栏：动态手稿 (主编辑器)

实现: 直接利用VS Code主编辑器，用户编辑标准的 Markdown 文件。

功能: AI代理通过调用 vscode.workspace.applyEdit API，以非破坏性的方式（如插入、差异视图建议）与文档交互，确保用户始终拥有最终控制权。

右栏：AI代理控制面板 (Webview)

实现: 在编辑器旁打开一个基于 React 和 Webview UI Toolkit 构建的Webview面板。

功能: 作为人机协作的“驾驶舱”，包含任务控制台（自然语言指令）、“思考链”实时可视化器，以及用于“人在环路”决策的动态交互模块（如批准/拒绝卡片）。

第4章：后端智能核心：LangGraph 科研代理
后端的AI代理将基于LangGraph构建一个模块化的四阶段工作流，并具备强大的容错能力。

4.1 四阶段科研工作流
阶段一：智能文献发现

流程: 接收主题 -> LLM头脑风暴生成查询 -> 智能选择API工具 -> 执行搜索 -> 综合与去重。

工具集: ArxivSearchTool, PubMedTool, SemanticScholarTool。

阶段二：自动化资源管理

流程: 遍历文献列表 -> 尝试获取全文PDF -> 系统性归档。

工具集: UnpaywallTool (查找开放获取PDF), ZoteroTool (在Zotero中创建条目并附加PDF)。

阶段三：基于RAG的知识合成

流程: 提取PDF文本 -> 分块 -> 向量化 -> 索引至pgvector -> 构建即时RAG知识库。

能力: 实现对文献内容的精确问答、跨文档综合和结构化信息提取。

阶段四：自动化报告生成与引文规范化

流程: 综合前序阶段成果 -> LLM生成Markdown报告 -> 格式化引文。

工具集: ZoteroTool (利用Zotero强大的API生成符合任意格式要求的参考文献列表)。

4.2 为失败而设计：高级错误处理
我们将借鉴成熟工作流平台的思想，在LangGraph中构建弹性的错误处理机制。通过条件边（Conditional Edges），将可能失败的节点连接到错误路由节点，实现：

指数退避重试: 针对网络抖动等瞬时错误。

优雅失败: 针对API密钥错误等永久性错误，向UI报告清晰信息并终止工作流，而非使系统崩溃。

第5章：分阶段开发路线图
我们将采用敏捷开发模式，分三个阶段交付平台核心价值。

阶段一：后端基础与核心代理 (预计4周)

核心目标: 搭建一个功能稳定、可通过API调用的“无头”AI代理。

可交付成果: 功能性的FastAPI服务器，配置好的PostgreSQL数据库，一个能完整执行四阶段工作流的线性LangGraph代理。

验收标准: 能通过API测试工具触发任务，并在数据库中验证所有产出数据的正确性。

阶段二：VS Code骨架与静态展示 (预计4周)

核心目标: 创建一个能“看见”并静态展示后端数据的VS Code插件（只读）。

可交付成果: 一个基本的VS Code插件，能在启动时从后端获取数据，并将其分别渲染到主编辑器、侧边栏树视图和Webview面板中，符合三栏式布局。

验收标准: 用户安装插件后，能看到一个已完成任务的静态视图。

阶段三：实时交互与动态协作 (预计5周)

核心目标: 打通前后端实时双向通信，激活所有交互功能。

可交付成果: 稳定的WebSocket连接；用户可通过Webview控制台下达指令；AI对文档的修改能实时、平滑地反映在编辑器中；实现一个基础的“人在环路”决策流程。

验收标准: 用户能与AI进行多轮交互，并能在关键节点上干预AI的行为。

第6章：部署与运维
我们将采用基于容器化的生产环境部署策略，确保平台的稳定性与安全性。

容器化与编排: 所有服务（FastAPI后端、PostgreSQL数据库）都将被打包成独立的 Docker 镜像，并通过一个 docker-compose.yml 文件进行统一编排和管理。

密钥与配置管理: 严格禁止将任何敏感信息硬编码在代码中。所有密钥将通过 .env 文件进行管理，并在容器启动时作为环境变量注入。.env 文件必须被添加到 .gitignore 中。

数据持久化: 使用Docker的 卷（Volumes） 功能，将PostgreSQL的数据目录映射到宿主机服务器的持久化存储路径，确保数据在容器重启或更新后依然安全。

第7章：总结与下一步
本规划详细阐述了如何将 gemini-fullstack-langgraph-quickstart 项目，从一个简单的Web演示，系统性地升级为一个深度集成于VS Code的、强大的自动化科研平台。

完成上述三个阶段的开发后，平台将具备坚实的核心功能。未来的发展方向将包括：深化“人在环路”的协同编辑能力、构建面向特定学科的可插拔工具架构，以及最终演进为一个支持团队协作、倡导开放科学的下一代科研生态系统。